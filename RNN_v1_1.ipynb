{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN v1_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mojn2000/DeepProject/blob/main/RNN_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQcwPFm4rS84",
        "outputId": "118fc38e-74e7-4894-ecb5-b84502c9c029"
      },
      "source": [
        "!pip3 install pickle5\n",
        "import pickle5 as pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_path = 'drive/My Drive/Skole/Uni/9_semester/02456_deep_learning/Project/'\n",
        "\n",
        "if (not(os.path.exists(drive_path))):\n",
        "  drive_path = 'drive/MyDrive/DL project/'  # Idas path    \n",
        "\n",
        "f0 = \"padded_data.pickle\"\n",
        "\n",
        "## LOAD PADDED and CLEANED data \n",
        "with open(drive_path + f0, 'rb') as f:\n",
        "    data = pickle.load(f)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B22Tj0P2cVTb"
      },
      "source": [
        "# Load functions\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
        "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax, leaky_relu, linear \n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dZYr_0ztq6b"
      },
      "source": [
        "Separate into test, train, and bumpy roads "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkJzeAN3tye9"
      },
      "source": [
        "# Definition of bumpy road in IRI terms \n",
        "tau = 4.5 \n",
        "\n",
        "good_data = data[data['IRI_mean'] <= tau]\n",
        "bad_data = data[data['IRI_mean'] > tau]\n",
        "\n",
        "\n",
        "# Separate good_data into test and train sets \n",
        "n = 2500 # sample size of train set\n",
        "\n",
        "good_train, good_test = train_test_split(good_data, test_size=0.2)\n",
        "#bad_train, bad_test = train_test_split(bad_data, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZQBroJnxqux"
      },
      "source": [
        "# Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZW_EyvxcppL",
        "outputId": "d0be4800-c551-4a6b-819f-4acd9369075e"
      },
      "source": [
        "train_data = []\n",
        "test_data = []\n",
        "test_bad = []\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# test data\n",
        "for i in range(len(good_test['GM.acc.xyz.z'])):\n",
        "   #x_data = np.concatenate((good_test['GM.acc.xyz.z'].values[i].flatten(),good_test['GM.obd.spd_veh.value'].values[i].flatten()),axis=0)\n",
        "   x_data = good_test['GM.acc.xyz.z'].values[i].flatten()\n",
        "   labels = [i] * len(x_data)\n",
        "   test_data.append([x_data, labels])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# train data\n",
        "for i in range(len(good_train['GM.acc.xyz.z'])):\n",
        "   #x_data = np.concatenate((good_train['GM.acc.xyz.z'].values[i].flatten(),good_train['GM.obd.spd_veh.value'].values[i].flatten()),axis=0)\n",
        "   x_data = good_train['GM.acc.xyz.z'].values[i].flatten()\n",
        "   labels = [i] * len(x_data)\n",
        "   train_data.append([x_data, labels])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# bad data\n",
        "for i in range(len(bad_data['GM.acc.xyz.z'])):\n",
        "   #x_data = np.concatenate((bad_data['GM.acc.xyz.z'].values[i].flatten(),bad_data['GM.obd.spd_veh.value'].values[i].flatten()),axis=0)\n",
        "   x_data = bad_data['GM.acc.xyz.z'].values[i].flatten()\n",
        "   labels = [i] * len(x_data)\n",
        "   test_bad.append([x_data, labels])\n",
        "\n",
        "bad_loader = torch.utils.data.DataLoader(test_bad, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "\n",
        "i1, l1 = next(iter(train_loader))\n",
        "print(i1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3366])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkFAwBFytIjT"
      },
      "source": [
        "# RNN network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lulqvXEtHiw",
        "outputId": "6f5a6b81-17ab-40d2-8485-631a18922d6b"
      },
      "source": [
        "# define size variables\n",
        "# num_features = len(good_train['GM.acc.xyz.z'].values[0]) + len(good_train['GM.obd.spd_veh.value'].values[0])\n",
        "num_features = len(good_train['GM.acc.xyz.z'].values[0])\n",
        "hidden_units = 24 #40\n",
        "latent_features = 8 #8\n",
        "\n",
        "seq_len = 1\n",
        "n_features = num_features\n",
        "latent_dim = latent_features\n",
        "hidden_size = hidden_units\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, n_features, latent_dim, hidden_size):\n",
        "      super(EncoderRNN, self).__init__()\n",
        "\n",
        "      self.n_features = n_features\n",
        "      self.hidden_size = hidden_size\n",
        "      self.latent_dim = latent_dim\n",
        "\n",
        "      self.gru_enc = nn.GRU(n_features, hidden_size,\n",
        "                        batch_first = True,dropout=0, # tried dropout, not effecttive\n",
        "                        bidirectional=True)\n",
        "      \n",
        "      self.lat_layer = nn.GRU(hidden_size*2, latent_dim,\n",
        "                        batch_first = True, dropout=0,\n",
        "                        bidirectional = False)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x, _  = self.gru_enc(x)\n",
        "      x , h = self.lat_layer(x)\n",
        "      return x[:,-1].unsqueeze(1)\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, seq_len, n_features , latent_dim , hidden_size):\n",
        "      super(DecoderRNN, self).__init__()\n",
        "\n",
        "      self.seq_len = seq_len\n",
        "      self.n_features = n_features\n",
        "      self.latent_dim = latent_dim\n",
        "      self.hidden_size = hidden_size\n",
        "\n",
        "      self.gru_dec1 = nn.GRU(latent_dim, latent_dim,\n",
        "                      batch_first = True, dropout=0,\n",
        "                      bidirectional= False)\n",
        "\n",
        "      self.gru_dec2 = nn.GRU(latent_dim, hidden_size,\n",
        "                        batch_first = True, dropout=0,\n",
        "                        bidirectional= True)\n",
        "\n",
        "      self.output_layer = nn.Linear(self.hidden_size*2, n_features,bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x = x.repeat(1,self.seq_len, 1)\n",
        "      x, _ = self.gru_dec1(x)\n",
        "      x, _ = self.gru_dec2(x)\n",
        "      return (self.output_layer(x))\n",
        "\n",
        "\n",
        "class AERNN(nn.Module):\n",
        "    def __init__(self, seq_len, n_features, latent_dim , hidden_size):\n",
        "      super(AERNN, self).__init__()\n",
        "\n",
        "      self.seq_len = seq_len\n",
        "      self.encoder = EncoderRNN(n_features, latent_dim, hidden_size)\n",
        "      self.decoder = DecoderRNN(seq_len, n_features, latent_dim, hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x = self.encoder(x)\n",
        "      x = self.decoder(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "net = AERNN(seq_len, n_features, latent_dim , hidden_size)\n",
        "\n",
        "print(net)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AERNN(\n",
            "  (encoder): EncoderRNN(\n",
            "    (gru_enc): GRU(3366, 24, batch_first=True, bidirectional=True)\n",
            "    (lat_layer): GRU(48, 8, batch_first=True)\n",
            "  )\n",
            "  (decoder): DecoderRNN(\n",
            "    (gru_dec1): GRU(8, 8, batch_first=True)\n",
            "    (gru_dec2): GRU(8, 24, batch_first=True, bidirectional=True)\n",
            "    (output_layer): Linear(in_features=48, out_features=3366, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4r-4BTeyO8R"
      },
      "source": [
        "## Set network parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGqTXspN5hHk"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# if you want L2 regularization, then add weight_decay to SGD\n",
        "#optimizer = optim.Adam(net.parameters(), lr=1e-3,weight_decay=1e-4) #weight_decay=1e-2\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=1e-3,weight_decay=1e-4) #weight_decay=1e-4\n",
        "\n",
        "# custom loss function\n",
        "def loss_function(x_hat,x):\n",
        "\n",
        "    x_hat[x[:,:,:] == 0] = 0 \n",
        "\n",
        "    loss = torch.diagonal(torch.matmul(x_hat[:,0,:] - x[:,0,:],torch.transpose(x_hat[:,0,:] - x[:,0,:] ,0,1))) / torch.sum(x[:,0,:] != 0, dim = 1)\n",
        "    \n",
        "    return(sum(loss)/batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "fq8wL0IhfWTB"
      },
      "source": [
        "#@title\n",
        "import os\n",
        "from typing import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from IPython.display import Image, display, clear_output\n",
        "from sklearn.manifold import TSNE\n",
        "from torch import Tensor\n",
        "from torch.distributions import Normal\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "\n",
        "def plot_autoencoder_stats(\n",
        "        x: Tensor = None,\n",
        "        x_hat: Tensor = None,\n",
        "        z: Tensor = None,\n",
        "        y: Tensor = None,\n",
        "        epoch: int = None,\n",
        "        train_loss: List = None,\n",
        "        valid_loss: List = None,\n",
        "        classes: List = None,\n",
        "        dimensionality_reduction_op: Optional[Callable] = None,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    An utility \n",
        "    \"\"\"\n",
        "    # -- Plotting --\n",
        "    f, axarr = plt.subplots(2, 2, figsize=(20, 20))\n",
        "\n",
        "    # Loss\n",
        "    ax = axarr[0, 0]\n",
        "    ax.set_title(\"Error\")\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Error')\n",
        "\n",
        "    ax.plot(np.arange(epoch + 1), train_loss, color=\"black\")\n",
        "    ax.plot(np.arange(epoch + 1), valid_loss, color=\"gray\", linestyle=\"--\")\n",
        "    ax.legend(['Training error', 'Validation error'])\n",
        "\n",
        "    # Latent space\n",
        "    ax = axarr[0, 1]\n",
        "\n",
        "    ax.set_title('Latent space')\n",
        "    ax.set_xlabel('Dimension 1')\n",
        "    ax.set_ylabel('Dimension 2')\n",
        "\n",
        "    # If you want to use a dimensionality reduction method you can use\n",
        "    # for example TSNE by projecting on two principal dimensions\n",
        "    # TSNE.fit_transform(z)\n",
        "    if dimensionality_reduction_op is not None:\n",
        "        z = dimensionality_reduction_op(z)\n",
        "\n",
        "    colors = iter(plt.get_cmap('Set1')(np.linspace(0, 1.0, len(classes))))\n",
        "    for c in classes:\n",
        "        ax.scatter(*z[y.numpy() == c].T, c=next(colors), marker='o')\n",
        "\n",
        "    ax.legend(classes)\n",
        "\n",
        "    # Inputs\n",
        "    ax = axarr[1, 0]\n",
        "    ax.set_title('Inputs')\n",
        "    ax.axis('off')\n",
        "\n",
        "    rows = 8\n",
        "    batch_size = x.size(0)\n",
        "    columns = batch_size // rows\n",
        "\n",
        "    canvas = np.zeros((28 * rows, columns * 28))\n",
        "    for i in range(rows):\n",
        "        for j in range(columns):\n",
        "            idx = i % columns + rows * j\n",
        "            canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = x[idx].reshape((28, 28))\n",
        "    ax.imshow(canvas, cmap='gray')\n",
        "\n",
        "    # Reconstructions\n",
        "    ax = axarr[1, 1]\n",
        "    ax.set_title('Reconstructions')\n",
        "    ax.axis('off')\n",
        "\n",
        "    canvas = np.zeros((28 * rows, columns * 28))\n",
        "    for i in range(rows):\n",
        "        for j in range(columns):\n",
        "            idx = i % columns + rows * j\n",
        "            canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = x_hat[idx].reshape((28, 28))\n",
        "\n",
        "    ax.imshow(canvas, cmap='gray')\n",
        "\n",
        "    tmp_img = \"tmp_ae_out.png\"\n",
        "    plt.savefig(tmp_img)\n",
        "    plt.close(f)\n",
        "    display(Image(filename=tmp_img))\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    os.remove(tmp_img)\n",
        "\n",
        "\n",
        "def plot_samples(ax, x):\n",
        "    x = x.to('cpu')\n",
        "    nrow = int(np.sqrt(x.size(0)))\n",
        "    x_grid = make_grid(x.view(-1, 1, 28, 28), nrow=nrow).permute(1, 2, 0)\n",
        "    ax.imshow(x_grid)\n",
        "    ax.axis('off')\n",
        "\n",
        "\n",
        "def plot_interpolations(ax, vae):\n",
        "    device = next(iter(vae.parameters())).device\n",
        "    nrow = 10\n",
        "    nsteps = 10\n",
        "    prior_params = vae.prior_params.expand(2 * nrow, *vae.prior_params.shape[-1:])\n",
        "    mu, log_sigma = prior_params.chunk(2, dim=-1)\n",
        "    pz = Normal(mu, log_sigma.exp())\n",
        "    z = pz.sample().view(nrow, 2, -1)\n",
        "    t = torch.linspace(0, 1, 10, device=device)\n",
        "    zs = t[None, :, None] * z[:, 0, None, :] + (1 - t[None, :, None]) * z[:, 1, None, :]\n",
        "    px = vae.observation_model(zs.view(nrow * nsteps, -1))\n",
        "    x = px.sample()\n",
        "    x = x.to('cpu')\n",
        "    x_grid = make_grid(x.view(-1, 1, 28, 28), nrow=nrow).permute(1, 2, 0)\n",
        "    ax.imshow(x_grid)\n",
        "    ax.axis('off')\n",
        "\n",
        "\n",
        "def plot_grid(ax, vae):\n",
        "    device = next(iter(vae.parameters())).device\n",
        "    nrow = 10\n",
        "    xv, yv = torch.meshgrid([torch.linspace(-3, 3, 10), torch.linspace(-3, 3, 10)])\n",
        "    zs = torch.cat([xv[:, :, None], yv[:, :, None]], -1)\n",
        "    zs = zs.to(device)\n",
        "    px = vae.observation_model(zs.view(nrow * nrow, 2))\n",
        "    x = px.sample()\n",
        "    x = x.to('cpu')\n",
        "    x_grid = make_grid(x.view(-1, 1, 28, 28), nrow=nrow).permute(1, 2, 0)\n",
        "    ax.imshow(x_grid)\n",
        "    ax.axis('off')\n",
        "\n",
        "\n",
        "def plot_2d_latents(ax, qz, z, y):\n",
        "    z = z.to('cpu')\n",
        "    y = y.to('cpu')\n",
        "    scale_factor = 2\n",
        "    batch_size = z.shape[0]\n",
        "    palette = sns.color_palette()\n",
        "    colors = [palette[l] for l in y]\n",
        "\n",
        "    # plot prior\n",
        "    prior = plt.Circle((0, 0), scale_factor, color='gray', fill=True, alpha=0.1)\n",
        "    ax.add_artist(prior)\n",
        "\n",
        "    # plot data points\n",
        "    mus, sigmas = qz.mu.to('cpu'), qz.sigma.to('cpu')\n",
        "    mus = [mus[i].numpy().tolist() for i in range(batch_size)]\n",
        "    sigmas = [sigmas[i].numpy().tolist() for i in range(batch_size)]\n",
        "\n",
        "    posteriors = [\n",
        "        plt.matplotlib.patches.Ellipse(mus[i], *(scale_factor * s for s in sigmas[i]), color=colors[i], fill=False,\n",
        "                                       alpha=0.3) for i in range(batch_size)]\n",
        "    for p in posteriors:\n",
        "        ax.add_artist(p)\n",
        "\n",
        "    ax.scatter(z[:, 0], z[:, 1], color=colors)\n",
        "\n",
        "    ax.set_xlim([-3, 3])\n",
        "    ax.set_ylim([-3, 3])\n",
        "    ax.set_aspect('equal', 'box')\n",
        "\n",
        "\n",
        "def plot_latents(ax, z, y):\n",
        "    z = z.to('cpu')\n",
        "    palette = sns.color_palette()\n",
        "    colors = [palette[l] for l in y]\n",
        "    z = TSNE(n_components=2).fit_transform(z)\n",
        "    ax.scatter(z[:, 0], z[:, 1], color=colors)\n",
        "\n",
        "\n",
        "def make_vae_plots(vae, x, y, outputs, training_data, validation_data, tmp_img=\"tmp_vae_out.png\", figsize=(18, 18)):\n",
        "    fig, axes = plt.subplots(3, 3, figsize=figsize, squeeze=False)\n",
        "\n",
        "    # plot the observation\n",
        "    axes[0, 0].set_title(r'Observation $\\mathbf{x}$')\n",
        "    plot_samples(axes[0, 0], x)\n",
        "\n",
        "    # plot the latent samples\n",
        "    try:\n",
        "        z = outputs['z']\n",
        "        if z.shape[1] == 2:\n",
        "            axes[0, 1].set_title(r'Latent Samples $\\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$')\n",
        "            qz = outputs['qz']\n",
        "            plot_2d_latents(axes[0, 1], qz, z, y)\n",
        "        else:\n",
        "            axes[0, 1].set_title(r'Latent Samples $\\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$ (t-SNE)')\n",
        "            plot_latents(axes[0, 1], z, y)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate the plot of the latent sanples because of exception\")\n",
        "        print(e)\n",
        "\n",
        "    # plot posterior samples\n",
        "    axes[0, 2].set_title(\n",
        "        r'Reconstruction $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | \\mathbf{z}), \\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$')\n",
        "    px = outputs['px']\n",
        "    x_sample = px.sample().to('cpu')\n",
        "    plot_samples(axes[0, 2], x_sample)\n",
        "\n",
        "    # plot ELBO\n",
        "    ax = axes[1, 0]\n",
        "    ax.set_title(r'ELBO: $\\mathcal{L} ( \\mathbf{x} )$')\n",
        "    ax.plot(training_data['elbo'], label='Training')\n",
        "    ax.plot(validation_data['elbo'], label='Validation')\n",
        "    ax.legend()\n",
        "\n",
        "    # plot KL\n",
        "    ax = axes[1, 1]\n",
        "    ax.set_title(r'$\\mathcal{D}_{\\operatorname{KL}}\\left(q_\\phi(\\mathbf{z}|\\mathbf{x})\\ |\\ p(\\mathbf{z})\\right)$')\n",
        "    ax.plot(training_data['kl'], label='Training')\n",
        "    ax.plot(validation_data['kl'], label='Validation')\n",
        "    ax.legend()\n",
        "\n",
        "    # plot NLL\n",
        "    ax = axes[1, 2]\n",
        "    ax.set_title(r'$\\log p_\\theta(\\mathbf{x} | \\mathbf{z})$')\n",
        "    ax.plot(training_data['log_px'], label='Training')\n",
        "    ax.plot(validation_data['log_px'], label='Validation')\n",
        "    ax.legend()\n",
        "\n",
        "    # plot prior samples\n",
        "    axes[2, 0].set_title(r'Samples $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | \\mathbf{z}), \\mathbf{z} \\sim p(\\mathbf{z})$')\n",
        "    px = vae.sample_from_prior(batch_size=x.size(0))['px']\n",
        "    x_samples = px.sample()\n",
        "    plot_samples(axes[2, 0], x_samples)\n",
        "\n",
        "    # plot interpolations samples\n",
        "    axes[2, 1].set_title(\n",
        "        r'Latent Interpolations: $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | t \\cdot \\mathbf{z}_1 + (1-t) \\cdot \\mathbf{z}_2), \\mathbf{z}_1, \\mathbf{z}_2 \\sim p(\\mathbf{z}), t=0 \\dots 1$')\n",
        "    plot_interpolations(axes[2, 1], vae)\n",
        "\n",
        "    # plot samples (sampling from a grid instead of the prior)\n",
        "    if vae.latent_features == 2:\n",
        "        axes[2, 2].set_title(\n",
        "            r'Samples: $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | \\mathbf{z}), \\mathbf{z} \\sim \\operatorname{grid}(-3:3, -3:3)$')\n",
        "        px = vae.sample_from_prior(batch_size=x.size(0))['px']\n",
        "        x_samples = px.sample()\n",
        "        plot_grid(axes[2, 2], vae)\n",
        "\n",
        "    # display\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(tmp_img)\n",
        "    plt.close(fig)\n",
        "    display(Image(filename=tmp_img))\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    os.remove(tmp_img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ys17NlylEA"
      },
      "source": [
        "## Train the network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAJCt2886Cuz"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV8rxalFynLu",
        "outputId": "ac92f651-10e9-4c91-8b22-c2c50f30aa96"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    batch_loss = []\n",
        "    net.train()\n",
        "    \n",
        "    # Go through each batch in the training dataset using the loader\n",
        "    # Note that y is not necessarily known as it is here\n",
        "    for x,y in train_loader:\n",
        "        \n",
        "        x = x.float()\n",
        "        #print(x.shape)\n",
        "        x = x[:,None,:]\n",
        "        outputs = net(x)\n",
        "        x_hat = outputs\n",
        "        #x_hat = outputs['x_hat']\n",
        "        #x_hat = outputs[:,0,:]\n",
        "        #x = x[:,0,:]\n",
        "        #x_hat[x[:,:] == 0] = 0\n",
        "\n",
        "        # note, target is the original tensor, as we're working with auto-encoders\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss = loss_function(x_hat, x)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_loss.append(loss.item())\n",
        "\n",
        "    train_loss.append(np.mean(batch_loss))\n",
        "\n",
        "    # Evaluate, do not propagate gradients\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        \n",
        "        # Just load a single batch from the test loader\n",
        "        x, y = next(iter(test_loader))\n",
        "        \n",
        "        x = x.float()\n",
        "        x = x[:,None,:]\n",
        "        outputs = net(x)\n",
        "        x_hat = outputs\n",
        "\n",
        "        # We save the latent variable and reconstruction for later use\n",
        "        # we will need them on the CPU to plot\n",
        "        #x_hat = outputs['x_hat']\n",
        "        #x_hat[x[:,:] == 0] = 0\n",
        "\n",
        "        #z = outputs['z'].cpu().numpy()\n",
        "\n",
        "        loss = loss_function(x_hat, x)\n",
        "\n",
        "        valid_loss.append(loss.item())\n",
        "    \n",
        "    if epoch == 0:\n",
        "        continue\n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n",
            "Epoch:  1\n",
            "Epoch:  2\n",
            "Epoch:  3\n",
            "Epoch:  4\n",
            "Epoch:  5\n",
            "Epoch:  6\n",
            "Epoch:  7\n",
            "Epoch:  8\n",
            "Epoch:  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd2mKQZGvps9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAczrzL2kLbR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "len_epoch = range(len(train_loss))\n",
        "#len_epoch = len_epoch[0:19]\n",
        "\n",
        "plt.rcParams.update(plt.rcParamsDefault)\n",
        "\n",
        "plt.figure(dpi=800)\n",
        "plt.plot(len_epoch,np.log10(train_loss),color='r',label=\"Train loss\")\n",
        "plt.plot(len_epoch,np.log10(valid_loss),color='b', label= \"Validation loss\")\n",
        "#plt.plot(len_epoch,train_loss,color='r',label=\"Train loss\")\n",
        "#plt.plot(len_epoch,valid_loss,color='b', label= \"Validation loss\")\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log(MSE)\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyq6VCNx8DzL"
      },
      "source": [
        "sqerr_good = []\n",
        "for x,y in test_loader:\n",
        "  x = x.float()\n",
        "  x = x[:,None,:]\n",
        "  outputs = net(x)\n",
        "  x_hat = outputs#['x_hat']\n",
        "  x_hat[x==0] = 0\n",
        "  sqerr_good.extend((torch.diagonal(torch.matmul(x_hat[:,0,:] - x[:,0,:],torch.transpose(x_hat[:,0,:] - x[:,0,:] ,0,1))) / torch.sum(x[:,0,:] != 0, dim = 1)).tolist())\n",
        "  #for ii in range(x_hat.shape[0]):\n",
        "  #  sqerr_good.append(float(sum((x[ii,0,x[ii,0,:] != 0] - x_hat[ii,0,x[ii,0,:] != 0])**2)) / sum(x[ii,0,:] != 0))\n",
        "\n",
        "plt.hist(sqerr_good, bins = 40)\n",
        "plt.title(\"Test data\")\n",
        "plt.show()\n",
        "\n",
        "#print(x.shape)\n",
        "#print(x_hat.shape)\n",
        "#print(loss_function(x,x_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbmEM8v3DJCY"
      },
      "source": [
        "sqerr_bad = []\n",
        "for x,y in bad_loader:\n",
        "  x = x.float()\n",
        "  x = x[:,None,:]\n",
        "  outputs = net(x)\n",
        "  x_hat = outputs#['x_hat']\n",
        "  x_hat[x == 0] = 0\n",
        "  sqerr_bad.extend((torch.diagonal(torch.matmul(x_hat[:,0,:] - x[:,0,:],torch.transpose(x_hat[:,0,:] - x[:,0,:] ,0,1))) / torch.sum(x[:,0,:] != 0, dim = 1)).tolist())\n",
        "  #for ii in range(x_hat.shape[0]):\n",
        "    #sqerr_bad.append(float(sum((x[ii,0,x[ii,0,:] != 0] - x_hat[ii,0,x[ii,0,:] != 0])**2)) / sum(x[ii,0,:] != 0))\n",
        "    \n",
        "\n",
        "\n",
        "plt.hist(sqerr_bad, bins = 40)\n",
        "plt.title(\"Bad data\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4PmtRYt1HK8"
      },
      "source": [
        "plt.hist(sqerr_good, bins = 30, alpha=0.5, label='Good')\n",
        "plt.hist(sqerr_bad, bins = 30, alpha=0.5, label='Bad')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title(\"Network test for good and bad data\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_RXAZ1DEP8n",
        "outputId": "00b92041-affe-428c-e8ba-56a02f42404d"
      },
      "source": [
        "min(sqerr_good)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00039136569830588996"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drCXxb9avq9W"
      },
      "source": [
        "#Compute performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V56oFscXjSiK"
      },
      "source": [
        "Tried weight decay -> funky minimum \n",
        "Adam -> not as good as RSMprop\n",
        "Dropout -> also, no performance increase "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdV0OgTkvuu5",
        "outputId": "0394b628-448d-4991-9211-a1e5fac41c83"
      },
      "source": [
        "eps = 1e-6\n",
        "tau_min = min(min(sqerr_good),min(sqerr_bad)) - eps\n",
        "tau_max = max(max(sqerr_good),max(sqerr_bad)) + eps\n",
        "print(tau_min)\n",
        "print(tau_max)\n",
        "\n",
        "N = 100\n",
        "\n",
        "perf = np.array([np.zeros(N), np.zeros(N), np.zeros(N), np.zeros(N), np.zeros(N)])\n",
        "ii = 0\n",
        "for tau in np.linspace(tau_min, tau_max, num = N):\n",
        "  perf[0,ii] = tau\n",
        "  perf[1,ii] = sum(sqerr_good<tau)  # true positives\n",
        "  perf[2,ii] = sum(sqerr_good>=tau) # false positive \n",
        "  perf[3,ii] = sum(sqerr_bad<tau)   # false negatives\n",
        "  perf[4,ii] = sum(sqerr_bad>=tau) # true negatives\n",
        "  ii += 1\n",
        "\n",
        "perf = pd.DataFrame(perf)\n",
        "perf.to_pickle(drive_path+'RNN_v1_1.pickle')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0016087823390737177\n",
            "0.05447471304035187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0brNla02yAqd"
      },
      "source": [
        "def tpr(mat):\n",
        "  return (perf[1,:]/(perf[1,:]+perf[2,:]))  # TP / (TP+FP)\n",
        "\n",
        "def tnr(mat):\n",
        "  return (perf[4,:]/(perf[3,:]+perf[4,:]))  # TN / (TN+FN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WunLXr4S-Eck"
      },
      "source": [
        "perf = perf.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGtutWV516EI"
      },
      "source": [
        "plt.plot(tpr(perf),tnr(perf), marker=\".\")\n",
        "plt.plot([0,1],[1,0],linestyle = 'dashed')\n",
        "plt.xlabel('True positive rate', fontsize = 16)\n",
        "plt.ylabel('True negative rate',fontsize = 16)\n",
        "plt.title('Performance curve', fontsize = 20)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "AhBissKJ28Tq",
        "outputId": "a8c36966-d905-4fb4-ccf0-9919cd67859b"
      },
      "source": [
        "aux = perf[:,16]\n",
        "import seaborn as sn\n",
        "\n",
        "array = [[aux[1]/(aux[1]+aux[2]), aux[2]/(aux[1]+aux[2])],\n",
        "         [aux[3]/(aux[3]+aux[4]), aux[4]/(aux[3]+aux[4])] ]\n",
        "#array = array/(sum(aux[1:4]))*100\n",
        "\n",
        "df_cm = pd.DataFrame(array, ['Good', 'Bad'], ['Good', 'Bad'])\n",
        "sn.set(font_scale=1.2) # for label size\n",
        "sn.heatmap(df_cm, annot=True, cmap = sn.cm.rocket_r, annot_kws={\"size\": 16},vmin = 0, ) # font size\n",
        "plt.xlabel('Predicted',fontsize = 16)\n",
        "plt.ylabel('Reference',fontsize = 16)\n",
        "plt.title('Confusion matrix', fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkwPSZDt7Tq6",
        "outputId": "d36a968e-4318-4762-ca65-07b722ee430e"
      },
      "source": [
        "aux"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.21001065e-03, 5.27000000e+02, 1.07000000e+02, 2.73000000e+02,\n",
              "       3.89000000e+02])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}