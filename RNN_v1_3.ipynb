{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN v1_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mojn2000/DeepProject/blob/main/RNN_v1_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQcwPFm4rS84",
        "outputId": "d27e0c40-cbdb-4b31-85c3-9ae1d47e3b05"
      },
      "source": [
        "!pip3 install pickle5\n",
        "import pickle5 as pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_path = 'drive/My Drive/Skole/Uni/9_semester/02456_deep_learning/Project/'\n",
        "\n",
        "if (not(os.path.exists(drive_path))):\n",
        "  drive_path = 'drive/MyDrive/DL project/'  # Idas path    \n",
        "\n",
        "f0 = \"padded_data.pickle\"\n",
        "\n",
        "## LOAD PADDED and CLEANED data \n",
        "with open(drive_path + f0, 'rb') as f:\n",
        "    data = pickle.load(f)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B22Tj0P2cVTb"
      },
      "source": [
        "# Load functions\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
        "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax, leaky_relu, linear \n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dZYr_0ztq6b"
      },
      "source": [
        "Separate into test, train, and bumpy roads "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkJzeAN3tye9"
      },
      "source": [
        "# Definition of bumpy road in IRI terms \n",
        "tau = 4.5 \n",
        "\n",
        "good_data = data[data['IRI_mean'] <= tau]\n",
        "bad_data = data[data['IRI_mean'] > tau]\n",
        "\n",
        "# Separate good_data into test and train sets \n",
        "good_train, good_test = train_test_split(good_data, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZQBroJnxqux"
      },
      "source": [
        "# Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZW_EyvxcppL"
      },
      "source": [
        "train_data = []\n",
        "test_data = []\n",
        "test_bad = []\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Test data\n",
        "for i in range(len(good_test['GM.acc.xyz.z'])):\n",
        "   x_data = good_test['GM.acc.xyz.z'].values[i].flatten()\n",
        "   labels = [i] * len(x_data)\n",
        "   test_data.append([x_data, labels])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# Train data\n",
        "for i in range(len(good_train['GM.acc.xyz.z'])):\n",
        "   x_data = good_train['GM.acc.xyz.z'].values[i].flatten()\n",
        "   labels = [i] * len(x_data)\n",
        "   train_data.append([x_data, labels])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# Bad data\n",
        "for i in range(len(bad_data['GM.acc.xyz.z'])):\n",
        "   x_data = bad_data['GM.acc.xyz.z'].values[i].flatten()\n",
        "   labels = [i] * len(x_data)\n",
        "   test_bad.append([x_data, labels])\n",
        "\n",
        "bad_loader = torch.utils.data.DataLoader(test_bad, shuffle=True, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkFAwBFytIjT"
      },
      "source": [
        "# RNN network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lulqvXEtHiw",
        "outputId": "0001440e-f2b7-4cbc-d28d-e350edafc495"
      },
      "source": [
        "# Define size variables\n",
        "\n",
        "num_features = len(good_train['GM.acc.xyz.z'].values[0])\n",
        "hidden_units = 24 \n",
        "latent_features = 8  \n",
        "layer_dim = 2 \n",
        "dropout_prob = 0.1 #0.2\n",
        "\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, hidden_units, latent_features):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        # ENCODER\n",
        "        self.rnn_in = nn.GRU(num_features,(hidden_units*1), layer_dim, batch_first=True, dropout=dropout_prob)\n",
        "        self.linear_in2 = nn.Linear(in_features=hidden_units, out_features=latent_features)\n",
        "        \n",
        "        # ------------------\n",
        "        # BOTTLE NECK\n",
        "        # ------------------  \n",
        "\n",
        "        # DECODER\n",
        "        self.rnn_out = nn.GRU((latent_features), (hidden_units*1),layer_dim,batch_first=True, dropout=dropout_prob)\n",
        "        self.linear_out0 = nn.Linear(in_features=(hidden_units*1), out_features=num_features,bias=True)\n",
        "\n",
        "\n",
        "    def forward(self, x): \n",
        "        outputs = {}\n",
        "        \n",
        "        # RNN\n",
        "        x = x[None,:, :]\n",
        "        x, h = self.rnn_in(x)\n",
        "\n",
        "        # LINEAR\n",
        "        x = x[0, :, :]\n",
        "        x = self.linear_in2(x)\n",
        "        z = x\n",
        "\n",
        "        # ------------------\n",
        "        # BOTTLE NECK\n",
        "        # ------------------        \n",
        "        \n",
        "        x = x[None,:, :]\n",
        "\n",
        "        # RNN\n",
        "        x, h = self.rnn_out(x)\n",
        "        x = x[0, :, :]\n",
        "\n",
        "        # LINEAR\n",
        "        x = self.linear_out0(x)\n",
        "        x_hat = x\n",
        "\n",
        "\n",
        "        return {\n",
        "            'z': z,\n",
        "            'x_hat': x_hat\n",
        "        }\n",
        "\n",
        "\n",
        "# Choose the shape of the autoencoder\n",
        "net = AutoEncoder(hidden_units=hidden_units, latent_features=latent_features)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoEncoder(\n",
            "  (rnn_in): GRU(3366, 24, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (linear_in2): Linear(in_features=24, out_features=8, bias=True)\n",
            "  (rnn_out): GRU(8, 24, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (linear_out0): Linear(in_features=24, out_features=3366, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4r-4BTeyO8R"
      },
      "source": [
        "## Set network parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGqTXspN5hHk"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#OPTIMIZER\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-4) \n",
        "\n",
        "\n",
        "# Custom loss function\n",
        "def loss_function(x_hat,x):\n",
        "\n",
        "    x_hat[x[:,:] == 0] = 0 \n",
        "\n",
        "    loss = torch.diagonal(torch.matmul(x_hat - x,torch.transpose(x_hat - x ,0,1))) / torch.sum(x[:,:] != 0, dim = 1)\n",
        "    #torch.sum((torch.abs(x_hat - x)), dim = 1) / torch.sum(x[:,:] != 0, dim = 1)\n",
        "\n",
        "    return(sum(loss)/batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ys17NlylEA"
      },
      "source": [
        "## Train the network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAJCt2886Cuz"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV8rxalFynLu"
      },
      "source": [
        "# EPOCHS\n",
        "num_epochs = 10\n",
        "\n",
        "# TRAIN MODEL\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    batch_loss = []\n",
        "    net.train()\n",
        "    \n",
        "    for x,y in train_loader:\n",
        "        x = x.float()\n",
        "        outputs = net(x)\n",
        "        x_hat = outputs['x_hat']\n",
        "\n",
        "        # LOSS\n",
        "        loss = loss_function(x_hat, x)\n",
        "        \n",
        "        # UPDATE MODEL\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_loss.append(loss.item())\n",
        "\n",
        "    train_loss.append(np.mean(batch_loss))\n",
        "\n",
        "    # Evaluate, do not propagate gradients\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "      \n",
        "        x, y = next(iter(test_loader))\n",
        "        x = x.float()\n",
        "        outputs = net(x)\n",
        "\n",
        "        x_hat = outputs['x_hat']\n",
        "        z = outputs['z'].cpu().numpy()\n",
        "\n",
        "        loss = loss_function(x_hat, x)\n",
        "\n",
        "        valid_loss.append(loss.item())\n",
        "    \n",
        "    if epoch == 0:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAczrzL2kLbR"
      },
      "source": [
        "# PLOT TRAINING CURVE \n",
        "import matplotlib.pyplot as plt\n",
        "len_epoch = range(len(train_loss))\n",
        "\n",
        "plt.rcParams.update(plt.rcParamsDefault)\n",
        "plt.figure(dpi=800)\n",
        "plt.plot(len_epoch,np.log10(train_loss),color='C3',label=\"Train loss\")\n",
        "plt.plot(len_epoch,np.log10(valid_loss),color='b', label= \"Validation loss\")\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log(MSE)\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyq6VCNx8DzL"
      },
      "source": [
        "# PLOT TEST\n",
        "sqerr_good = []\n",
        "for x,y in test_loader:\n",
        "  x = x.float()\n",
        "  outputs = net(x)\n",
        "  x_hat = outputs['x_hat']\n",
        "  x_hat[x==0] = 0\n",
        "  sqerr_good.extend((torch.diagonal(torch.matmul(x_hat - x,torch.transpose(x_hat - x ,0,1))) / torch.sum(x[:,:] != 0, dim = 1)).tolist())\n",
        "\n",
        "\n",
        "# PLOT TRAIN \n",
        "sqerr_good_train = []\n",
        "for x,y in train_loader:\n",
        "  x = x.float()\n",
        "  outputs = net(x)\n",
        "  x_hat = outputs['x_hat']\n",
        "  x_hat[x==0] = 0\n",
        "  sqerr_good_train.extend((torch.diagonal(torch.matmul(x_hat - x,torch.transpose(x_hat - x ,0,1))) / torch.sum(x[:,:] != 0, dim = 1)).tolist())\n",
        "\n",
        "\n",
        "# PLOT BAD \n",
        "sqerr_bad = []\n",
        "for x,y in bad_loader:\n",
        "  x = x.float()\n",
        "  outputs = net(x)\n",
        "  x_hat = outputs['x_hat']\n",
        "  x_hat[x==0] = 0\n",
        "  sqerr_bad.extend((torch.diagonal(torch.matmul(x_hat - x,torch.transpose(x_hat - x ,0,1))) / torch.sum(x[:,:] != 0, dim = 1)).tolist())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4PmtRYt1HK8"
      },
      "source": [
        "# PLOTTING OF RESULTS \n",
        "\n",
        "plt.hist(sqerr_good, bins = 30, alpha=0.5, label='Test',density = True)\n",
        "#plt.hist(sqerr_good_train, bins = 30, alpha=0.5, label='Train',density = True)\n",
        "plt.hist(sqerr_bad, bins = 30, alpha=0.5, label='Bad',density = True)\n",
        "plt.legend(loc='upper right')\n",
        "plt.title(\"Network test for good and bad data\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfT4OVdQG4Y0"
      },
      "source": [
        "#Compute performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpc8nOEmG36T",
        "outputId": "98691398-65b8-4aff-a5f9-66ce4b3f778b"
      },
      "source": [
        "from math import log10\n",
        "\n",
        "eps = 1e-6\n",
        "tau_min = min(min(sqerr_good),min(sqerr_bad)) - eps\n",
        "tau_max = max(max(sqerr_good),max(sqerr_bad)) + eps\n",
        "print(tau_min)\n",
        "print(tau_max)\n",
        "\n",
        "N = 100\n",
        "\n",
        "perf = np.array([np.zeros(N), np.zeros(N), np.zeros(N), np.zeros(N), np.zeros(N)])\n",
        "ii = 0\n",
        "#for tau in np.linspace(tau_min, tau_max, num = N):\n",
        "for tau in np.logspace(log10(tau_min), log10(tau_max), num = N):\n",
        "  perf[0,ii] = tau\n",
        "  perf[1,ii] = sum(sqerr_good<tau)  # true positives\n",
        "  perf[2,ii] = sum(sqerr_good>=tau) # false positive \n",
        "  perf[3,ii] = sum(sqerr_bad<tau)   # false negatives\n",
        "  perf[4,ii] = sum(sqerr_bad>=tau) # true negatives\n",
        "  ii += 1\n",
        "\n",
        "perf = pd.DataFrame(perf)\n",
        "perf.to_pickle(drive_path+'RNN_v1_3.pickle')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.217727820714936e-05\n",
            "0.055485384298324586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DBEsRDgNzga"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}